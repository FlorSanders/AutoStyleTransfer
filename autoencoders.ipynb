{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreloading makes development easier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow[and-cuda]==2.11\n",
    "#!pip install tensorflow_probability==0.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as krs\n",
    "import tensorflow_probability as tfp\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tools.audio_tools import read_audio, write_audio, play_audio\n",
    "from tools.feature_tools import compute_mels, compute_imels, compute_mfcc, compute_imfcc, load_data, normalize_features, denormalize_features\n",
    "from tools.constants import npy_classical_path, npy_jazz_path, models_path\n",
    "from tools.plot_tools import make_figax, plot_history, plot_audio, plot_spectral_feature\n",
    "from tools.tensorflow_tools import tune_hyperparameters, load_optimal_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.constants import npy_classical_path, npy_jazz_path, models_path\n",
    "from tools.feature_tools import compute_mels, compute_imels, compute_mfcc, compute_imfcc, load_data, normalize_features, denormalize_features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tools.plot_tools import make_figax, plot_history, plot_audio, plot_spectral_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Audio & Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(os.listdir(npy_classical_path)) = }\")\n",
    "print(f\"{len(os.listdir(npy_jazz_path)) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples from both styles\n",
    "n_samples = 1000\n",
    "n_samples = min(n_samples, len(os.listdir(npy_classical_path)), len(os.listdir(npy_jazz_path)))\n",
    "print(f\"{n_samples = }\")\n",
    "X_classical_raw = load_data(npy_classical_path, n_samples=n_samples)\n",
    "X_jazz_raw = load_data(npy_jazz_path, n_samples=n_samples)\n",
    "\n",
    "# Concatenate (train on all samples)\n",
    "X_raw = np.concatenate((X_classical_raw, X_jazz_raw))\n",
    "\n",
    "# Print feature shape\n",
    "print(f\"{X_raw.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Validation - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of data to keep apart for validation\n",
    "test_size = round(0.1 * len(X_raw))\n",
    "val_size = test_size\n",
    "# Perform split\n",
    "X_raw_train, X_raw_test = train_test_split(X_raw, test_size=test_size, random_state=1234)\n",
    "X_raw_train, X_raw_val = train_test_split(X_raw_train, test_size=val_size, random_state=1234)\n",
    "# Verify split shapes\n",
    "print(f\"{X_raw_train.shape = }\")\n",
    "print(f\"{X_raw_test.shape = }\")\n",
    "print(f\"{X_raw_val.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_raw_train.shape[1:]\n",
    "print(f\"{input_shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform normalization\n",
    "X_train, X_val, X_test = normalize_features(X_raw_train, X_raw_val=X_raw_val, X_raw_test=X_raw_test)\n",
    "\n",
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{X_val.shape = }\")\n",
    "print(f\"{X_test.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the effect of normalization\n",
    "fig, ax = make_figax()\n",
    "ax.plot(np.std(X_raw_train, axis=(0,1,3)), label=\"std\")\n",
    "ax.plot(np.mean(X_raw_train, axis=(0,1,3)), label=\"mean\")\n",
    "#ax.plot(np.max(X_raw_train, axis=(0,1,3)), label=\"max\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "#ax.set_title(\"Raw\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\"./results\", \"DataExploration\", \"distribution_raw.png\"), dpi=300, facecolor=\"white\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = make_figax()\n",
    "ax.plot(np.std(X_train, axis=(0,1,3)), label=\"std\")\n",
    "ax.plot(np.mean(X_train, axis=(0,1,3)), label=\"mean\")\n",
    "#ax.plot(np.max(X_train, axis=(0,1,3)), label=\"max\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "#ax.set_title(\"Normalized\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\"./results\", \"DataExploration\", \"distribution_preprocessed.png\"), dpi=300, facecolor=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nop = lambda x: x\n",
    "\n",
    "def test_autoencoder(autoencoder, test_set = X_test, plot_transforms = True, plot_raw_transforms = True, plot_waveforms = True):\n",
    "  # Pick sample at random\n",
    "  print(\"Picking Sample\")\n",
    "  choice = np.random.choice(len(test_set))\n",
    "  x = test_set[choice]\n",
    "\n",
    "  # Autencoder\n",
    "  print(\"Autencoding\")\n",
    "  x_hat = np.array(autoencoder(x.reshape((1, *x.shape))))\n",
    "\n",
    "  if plot_transforms:\n",
    "    print(\"Plotting transforms\")\n",
    "    fig, ax = plot_spectral_feature(x, fn=nop)\n",
    "    ax.set_title(\"Original Preprocessed Spectrum\")\n",
    "    fig, ax = plot_spectral_feature(x_hat, fn=nop)\n",
    "    ax.set_title(\"Reconstructed Preprocessed Spectrum\")\n",
    "    plt.show()\n",
    "\n",
    "  # Postprocess\n",
    "  print(\"Postprocessing\")\n",
    "  x_raw = denormalize_features(x.reshape((1, *x.shape)))[0]\n",
    "  x_raw_hat = denormalize_features(x_hat.reshape((1, *x.shape)))[0]\n",
    "\n",
    "  if plot_raw_transforms:\n",
    "    print(\"Plotting transforms\")\n",
    "    fig, ax = plot_spectral_feature(x_raw)\n",
    "    ax.set_title(\"Original Raw Spectrum\")\n",
    "    fig, ax = plot_spectral_feature(x_raw_hat)\n",
    "    ax.set_title(\"Reconstructed Raw Spectrum\")\n",
    "    plt.show()\n",
    "\n",
    "  # Reconstruct Audio\n",
    "  print(\"Reconstructing Audio\")\n",
    "  s = np.squeeze(compute_imels(x_raw))\n",
    "  s_hat = np.squeeze(compute_imels(x_raw_hat))\n",
    "\n",
    "  if plot_waveforms:\n",
    "    fig, ax = plot_audio(s)\n",
    "    ax.set_title(\"Original Waveform\")\n",
    "    fig, ax = plot_audio(s_hat)\n",
    "    ax.set_title(\"Reconstructed Waveform\")\n",
    "    plt.show()\n",
    "\n",
    "  # Play audio\n",
    "  print(\"Original Audio\")\n",
    "  player = play_audio(s)\n",
    "  print(\"Reconstructed Audio\")\n",
    "  player = play_audio(s_hat)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_memory(autoencoder):\n",
    "  krs.backend.clear_session()\n",
    "  del autoencoder.encoder\n",
    "  del autoencoder.decoder\n",
    "  del autoencoder\n",
    "  krs.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(models_path, exist_ok = True)\n",
    "def save_autoencoder(autoencoder, params, history, name):\n",
    "    # Define and make directory\n",
    "    autoencoder_path = os.path.join(models_path, name)\n",
    "    os.makedirs(autoencoder_path, exist_ok = True)\n",
    "    \n",
    "    # Save parameters\n",
    "    with open(os.path.join(autoencoder_path, \"params.json\"), \"w\") as params_file:\n",
    "        json.dump(params, params_file)\n",
    "        \n",
    "    # Save history\n",
    "    with open(os.path.join(autoencoder_path, \"history.json\"), \"w\") as history_file:\n",
    "        if not isinstance(history, dict):\n",
    "            history = history.history\n",
    "        json.dump(history, history_file)\n",
    "    \n",
    "    # Save model\n",
    "    autoencoder.save(os.path.join(autoencoder_path, \"model.keras\"))\n",
    "\n",
    "def load_autoencoder(name, load_model = True):\n",
    "    # Define path\n",
    "    autoencoder_path = os.path.join(models_path, name)\n",
    "    \n",
    "    # Load parameters\n",
    "    with open(os.path.join(autoencoder_path, \"params.json\"), \"r\") as params_file:\n",
    "        params = json.load(params_file)\n",
    "    \n",
    "    # Load history\n",
    "    with open(os.path.join(autoencoder_path, \"history.json\"), \"r\") as history_file:\n",
    "        history = json.load(history_file)\n",
    "    \n",
    "    # Load model\n",
    "    autoencoder = None\n",
    "    if load_model:\n",
    "        autoencoder = krs.models.load_model(os.path.join(autoencoder_path, \"model.keras\"))\n",
    "    \n",
    "    return autoencoder, params, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.autoencoders import Conv2DAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"compression\": 4,\n",
    "    \"kernel_size\": 3,\n",
    "    \"conv_depth\": 1,\n",
    "    \"input_chans_multiplier\": 1,\n",
    "    \"skip_connection\": False,\n",
    "    \"pooling_type\": \"average\",\n",
    "}\n",
    "\n",
    "compile_kwargs = {\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"mae\",\n",
    "}\n",
    "\n",
    "results_path = os.path.join(\"./results/Conv2DAutoencoder\")\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test training\n",
    "autoencoder = Conv2DAutoencoder(**default_params)\n",
    "autoencoder.compile(**compile_kwargs)\n",
    "history = autoencoder.fit(X_train, X_train, epochs=1, shuffle=True, validation_data=(X_val, X_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "keys = np.array([\n",
    "    \"input_chans_multiplier\",\n",
    "    \"conv_depth\",\n",
    "    \"kernel_size\",\n",
    "    \"pooling_type\",\n",
    "])\n",
    "vals = np.array([\n",
    "    [1, 2, 4],\n",
    "    [1, 2, 3],\n",
    "    [3, 5],\n",
    "    [\"max\", \"average\"],\n",
    "], dtype=\"object\")\n",
    "loss_key = \"val_loss\"\n",
    "epochs = 250\n",
    "passes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random optimization\n",
    "optimal_params, optimal_loss = tune_hyperparameters(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    Conv2DAutoencoder,\n",
    "    default_params,\n",
    "    keys,\n",
    "    vals,\n",
    "    loss_key,\n",
    "    X_val=X_val,\n",
    "    y_val=X_val,\n",
    "    results_path=results_path,\n",
    "    epochs=epochs,\n",
    "    compile_kwargs=compile_kwargs,\n",
    "    verbose=False,\n",
    "    do_random=True,\n",
    "    random_attempts=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{optimal_params = }\")\n",
    "print(f\"{optimal_loss = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential optimization\n",
    "for i in range(passes):\n",
    "    # Random optimization\n",
    "    permutation = np.random.permutation(len(keys))\n",
    "    optimal_params, optimal_loss = tune_hyperparameters(\n",
    "        X_train,\n",
    "        X_train,\n",
    "        Conv2DAutoencoder,\n",
    "        optimal_params,\n",
    "        keys[permutation],\n",
    "        vals[permutation],\n",
    "        loss_key,\n",
    "        X_val=X_val,\n",
    "        y_val=X_val,\n",
    "        results_path=results_path,\n",
    "        epochs=epochs,\n",
    "        compile_kwargs=compile_kwargs,\n",
    "        verbose=False,\n",
    "        do_random=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{optimal_params = }\")\n",
    "print(f\"{optimal_loss = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimal hyperparameters from tuning process\n",
    "optimal_params, optimal_loss = load_optimal_params(results_path, loss_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{optimal_params = }\")\n",
    "print(f\"{optimal_loss = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual tuning\n",
    "optimal_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"compression\": 4,\n",
    "    \"kernel_size\": 5,\n",
    "    \"conv_depth\": 4,\n",
    "    \"input_chans_multiplier\": 1,\n",
    "    \"skip_connection\": True,\n",
    "    \"pooling_type\": \"average\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with optimal params\n",
    "autoencoder = Conv2DAutoencoder(**optimal_params)\n",
    "autoencoder.compile(**compile_kwargs)\n",
    "earlystopping = krs.callbacks.EarlyStopping(monitor=loss_key, patience=5, min_delta=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs=250, shuffle=True, validation_data=(X_val, X_val), callbacks=[earlystopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "autoencoder.save_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure loading works\n",
    "autoencoder = Conv2DAutoencoder(**optimal_params)\n",
    "autoencoder.load_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test autoencoder\n",
    "test_autoencoder(autoencoder, X_test, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.autoencoders import VariationalAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"compression\": 8,\n",
    "    \"kernel_size\": 3,\n",
    "    \"conv_depth\": 1,\n",
    "    \"input_chans_multiplier\": 1,\n",
    "    \"skip_connection\": False,\n",
    "    \"pooling_type\": \"average\",\n",
    "    \"kl_reg\": 1,\n",
    "    \"vol_reg\": 1,\n",
    "}\n",
    "\n",
    "results_path = os.path.join(\"./results/VariationalAutoencoder\")\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Training\n",
    "autoencoder = VariationalAutoencoder(**default_params)\n",
    "autoencoder.compile(optimizer=\"adam\")\n",
    "history = autoencoder.fit(X_train, X_train, epochs=1, shuffle=True, validation_data=(X_val, X_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual parameter tuning\n",
    "optimal_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"compression\": 4,\n",
    "    \"kernel_size\": 5,\n",
    "    \"conv_depth\": 4,\n",
    "    \"input_chans_multiplier\": 1,\n",
    "    \"skip_connection\": True,\n",
    "    \"pooling_type\": \"average\",\n",
    "    \"kl_reg\": 1e-10,\n",
    "    \"vol_reg\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with all data & optimal parameters\n",
    "autoencoder = VariationalAutoencoder(**optimal_params)\n",
    "autoencoder.compile(optimizer=\"adam\")\n",
    "earlystopping = krs.callbacks.EarlyStopping(monitor=\"val_r_loss\", patience=5, min_delta=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs=10, shuffle=True, validation_data=(X_val, X_val), callbacks=[earlystopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "autoencoder.save_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoencoder\n",
    "autoencoder = VariationalAutoencoder(**optimal_params)\n",
    "autoencoder.load_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoencoder(autoencoder, X_test, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test creating multiple variations of the same input data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.autoencoders import GANGenerator, GANDiscriminator\n",
    "from models.layers import GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan_model(**params):\n",
    "    # Split generator & discriminator params\n",
    "    g_params = {}\n",
    "    d_params = {}\n",
    "    for key, value in params.items():\n",
    "        if key[:2] == \"g_\":\n",
    "            # Generator param\n",
    "            g_params[key[2:]] = value\n",
    "        elif key[:2] == \"d_\":\n",
    "            # Discriminator param\n",
    "            d_params[key[2:]] = value\n",
    "        else:\n",
    "            # Shared param\n",
    "            g_params[key] = value\n",
    "            d_params[key] = value\n",
    "    \n",
    "    # Instantiate model\n",
    "    generator = GANGenerator(**g_params)\n",
    "    discriminator = GANDiscriminator(**d_params)\n",
    "    gan = GAN(generator, discriminator)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"g_compression\": 8,\n",
    "    \"g_kernel_size\": 3,\n",
    "    \"g_conv_depth\": 1,\n",
    "    \"g_input_chans_multiplier\": 1,\n",
    "    \"g_skip_connection\": False,\n",
    "    \"g_pooling_type\": \"average\",\n",
    "    \"g_gan_reg\": 0.1,\n",
    "    \"g_c_reg\": 0.1,\n",
    "    \"g_s_reg\": 0.1,\n",
    "    \"g_mode\": \"adain\",\n",
    "    \"g_hidden_activation\": \"relu\",\n",
    "    \"d_mlp_layers\": 2,\n",
    "    \"d_conv_layers\": 2,\n",
    "    \"d_conv_kernel_size\": 3,\n",
    "    \"d_conv_pooling_size\": 4,\n",
    "    \"d_conv_pooling_type\": \"max\",\n",
    "}\n",
    "\n",
    "compile_kwargs={\n",
    "    \"g_optimizer\": \"adam\",\n",
    "    \"d_optimizer\": \"adam\",\n",
    "}\n",
    "\n",
    "results_path = os.path.join(\"./results/GANAutoencoder\")\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test training\n",
    "gan = create_gan_model(**default_params)\n",
    "gan.compile(**compile_kwargs)\n",
    "history = gan.fit(X_train, X_train, epochs=1, shuffle=True, verbose=1, validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual parameter tuning\n",
    "optimal_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"g_compression\": 4,\n",
    "    \"g_kernel_size\": 5,\n",
    "    \"g_conv_depth\": 3,\n",
    "    \"g_input_chans_multiplier\": 1,\n",
    "    \"g_skip_connection\": True,\n",
    "    \"g_pooling_type\": \"average\",\n",
    "    \"g_gan_reg\": 0.025,\n",
    "    \"g_c_reg\": 0.01,\n",
    "    \"g_s_reg\": 0.01,\n",
    "    \"g_mode\": \"adain\",\n",
    "    \"g_hidden_activation\": \"relu\",\n",
    "    \"d_mlp_layers\": 2,\n",
    "    \"d_conv_layers\": 2,\n",
    "    \"d_conv_kernel_size\": 3,\n",
    "    \"d_conv_pooling_size\": 4,\n",
    "    \"d_conv_pooling_type\": \"max\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with optimal params\n",
    "gan = create_gan_model(**optimal_params)\n",
    "gan.compile(**compile_kwargs)\n",
    "earlystopping = krs.callbacks.EarlyStopping(monitor=\"val_r_loss\", patience=5, min_delta=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gan.fit(X_train, X_train, epochs=250, shuffle=True, verbose=1, callbacks=[earlystopping], validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "gan.generator.save_weights(os.path.join(results_path, \"generator\"))\n",
    "gan.discriminator.save_weights(os.path.join(results_path, \"discriminator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "gan = create_gan_model(**optimal_params)\n",
    "gan.generator.load_weights(os.path.join(results_path, \"generator\"))\n",
    "gan.discriminator.load_weights(os.path.join(results_path, \"discriminator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "def autoencoder_real(X):\n",
    "    X_real, X_fake = gan.generator(X)\n",
    "    return np.array(X_real)\n",
    "\n",
    "def autoencoder_fake(X):\n",
    "    X_real, X_fake = gan.generator(X)\n",
    "    return np.array(X_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoencoder(autoencoder_real, X_test, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoencoder(autoencoder_fake, X_test, False, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUNIT Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.autoencoders import MUNITGenerator, GANDiscriminator\n",
    "from models.layers import GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan_model(**params):\n",
    "    # Split generator & discriminator params\n",
    "    g_params = {}\n",
    "    d_params = {}\n",
    "    for key, value in params.items():\n",
    "        if key[:2] == \"g_\":\n",
    "            # Generator param\n",
    "            g_params[key[2:]] = value\n",
    "        elif key[:2] == \"d_\":\n",
    "            # Discriminator param\n",
    "            d_params[key[2:]] = value\n",
    "        else:\n",
    "            # Shared param\n",
    "            g_params[key] = value\n",
    "            d_params[key] = value\n",
    "    \n",
    "    # Instantiate model\n",
    "    generator = MUNITGenerator(**g_params)\n",
    "    discriminator = GANDiscriminator(**d_params)\n",
    "    gan = GAN(generator, discriminator)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"g_compression\": 8,\n",
    "    \"g_style_dim\": 8,\n",
    "    \"g_kernel_size\": 3,\n",
    "    \"g_conv_depth\": 1,\n",
    "    \"g_input_chans_multiplier\": 1,\n",
    "    \"g_skip_connection\": False,\n",
    "    \"g_pooling_type\": \"average\",\n",
    "    \"g_gan_reg\": 0.1,\n",
    "    \"g_c_reg\": 0.1,\n",
    "    \"g_s_reg\": 0.1,\n",
    "    \"g_adain_momentum\": 0.1,\n",
    "    \"g_adain_epsilon\": 1e-5,\n",
    "    \"d_mlp_layers\": 2,\n",
    "    \"d_conv_layers\": 2,\n",
    "    \"d_conv_kernel_size\": 3,\n",
    "    \"d_conv_pooling_size\": 4,\n",
    "    \"d_conv_pooling_type\": \"max\",\n",
    "}\n",
    "\n",
    "compile_kwargs={\n",
    "    \"g_optimizer\": \"adam\",\n",
    "    \"d_optimizer\": \"adam\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test training\n",
    "gan = create_gan_model(**default_params)\n",
    "gan.compile(**compile_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gan.fit(X_train, X_train, epochs=1, shuffle=True, verbose=1, validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual tuning\n",
    "results_path = os.path.join(\"./results/MUNITAutoencoder\")\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "optimal_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"g_compression\": 4,\n",
    "    \"g_style_dim\": 8,\n",
    "    \"g_kernel_size\": 5,\n",
    "    \"g_conv_depth\": 4,\n",
    "    \"g_input_chans_multiplier\": 1,\n",
    "    \"g_skip_connection\": False,\n",
    "    \"g_pooling_type\": \"average\",\n",
    "    \"g_gan_reg\": 0.01,\n",
    "    \"g_c_reg\": 0.01,\n",
    "    \"g_s_reg\": 0.01,\n",
    "    \"g_adain_momentum\": 0.1,\n",
    "    \"g_adain_epsilon\": 1e-5,\n",
    "    \"d_mlp_layers\": 2,\n",
    "    \"d_conv_layers\": 2,\n",
    "    \"d_conv_kernel_size\": 3,\n",
    "    \"d_conv_pooling_size\": 4,\n",
    "    \"d_conv_pooling_type\": \"max\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with optimal params\n",
    "gan = create_gan_model(**optimal_params)\n",
    "gan.compile(**compile_kwargs)\n",
    "earlystopping = krs.callbacks.EarlyStopping(monitor=\"val_r_loss\", patience=5, min_delta=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gan.fit(X_train, X_train, epochs=250, shuffle=True, verbose=1, callbacks=[earlystopping], validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "gan.generator.save(os.path.join(results_path, \"generator.keras\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "generator = krs.models.load_model(os.path.join(results_path, \"generator.keras\"))\n",
    "gan = GAN(generator, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "def autoencoder_real(X):\n",
    "    X_real, X_fake = gan.generator(X)\n",
    "    return np.array(X_real)\n",
    "\n",
    "def autoencoder_fake(X):\n",
    "    X_real, X_fake = gan.generator(X)\n",
    "    return np.array(X_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoencoder(autoencoder_real, X_test, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_autoencoder(autoencoder_fake, X_test, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
