{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transcoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreloading makes development easier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 19:24:41.884573: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-12 19:24:42.113330: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 19:24:42.113377: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 19:24:42.114631: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 19:24:42.217851: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-12 19:24:42.219852: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 19:24:43.708524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/florsanders/.local/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as krs\n",
    "import tensorflow_probability as tfp\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tools.audio_tools import read_audio, write_audio, play_audio\n",
    "from tools.feature_tools import compute_mels, compute_imels, compute_mfcc, compute_imfcc, load_data, normalize_features, denormalize_features\n",
    "from tools.constants import npy_classical_path, npy_jazz_path, models_path\n",
    "from tools.plot_tools import make_figax, plot_history, plot_audio, plot_spectral_feature\n",
    "from tools.tensorflow_tools import tune_hyperparameters, load_optimal_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.__version__ = '1.25.2'\n",
      "tf.__version__ = '2.14.0'\n",
      "tfp.__version__ = '0.22.1'\n",
      "sklearn.__version__ = '1.3.1'\n",
      "librosa.__version__ = '0.10.1'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__version__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msklearn\u001b[39m.\u001b[39m__version__ \u001b[39m= }\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlibrosa\u001b[39m.\u001b[39m__version__ \u001b[39m= }\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[39mprint\u001b[39m(__version__)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__version__' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import librosa\n",
    "print(f\"{np.__version__ = }\")\n",
    "print(f\"{tf.__version__ = }\")\n",
    "print(f\"{tfp.__version__ = }\")\n",
    "print(f\"{sklearn.__version__ = }\")\n",
    "print(f\"{librosa.__version__ = }\")\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Audio & Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "n_samples = min(n_samples, len(os.listdir(npy_classical_path)), len(os.listdir(npy_jazz_path)))\n",
    "print(f\"{n_samples = }\")\n",
    "\n",
    "X_c_raw = load_data(npy_classical_path, n_samples=n_samples)\n",
    "X_j_raw = load_data(npy_jazz_path, n_samples=n_samples)\n",
    "\n",
    "print(f\"{X_c_raw.shape = }\")\n",
    "print(f\"{X_j_raw.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Validation - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of data to keep apart for validation\n",
    "test_size = round(0.1 * n_samples)\n",
    "val_size = test_size\n",
    "# Perform splits\n",
    "X_c_raw_train, X_c_raw_test = train_test_split(X_c_raw, test_size=test_size, random_state=1234)\n",
    "X_c_raw_train, X_c_raw_val = train_test_split(X_c_raw_train, test_size=val_size, random_state=1234)\n",
    "X_j_raw_train, X_j_raw_test = train_test_split(X_j_raw, test_size=test_size, random_state=1234)\n",
    "X_j_raw_train, X_j_raw_val = train_test_split(X_j_raw_train, test_size=val_size, random_state=1234)\n",
    "# Verify split shapes\n",
    "print(f\"{X_c_raw_train.shape = }\")\n",
    "print(f\"{X_c_raw_test.shape = }\")\n",
    "print(f\"{X_c_raw_val.shape = }\")\n",
    "print(f\"{X_j_raw_train.shape = }\")\n",
    "print(f\"{X_j_raw_test.shape = }\")\n",
    "print(f\"{X_j_raw_val.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform normalization\n",
    "X_c_train, X_c_val, X_c_test = normalize_features(X_c_raw_train, X_raw_val=X_c_raw_val, X_raw_test=X_c_raw_test, name=\"classical\")\n",
    "X_j_train, X_j_val, X_j_test = normalize_features(X_j_raw_train, X_raw_val=X_j_raw_val, X_raw_test=X_j_raw_test, name=\"jazz\")\n",
    "\n",
    "print(f\"{X_c_train.shape }\")\n",
    "print(f\"{X_c_val.shape }\")\n",
    "print(f\"{X_c_test.shape }\")\n",
    "print(f\"{X_j_train.shape }\")\n",
    "print(f\"{X_j_val.shape }\")\n",
    "print(f\"{X_j_test.shape }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_c_train.shape[1:]\n",
    "\n",
    "print(f\"{input_shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Transfer Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test transcoder\n",
    "def test_transcoder(transcoder, X_test=X_c_test, Y_test=X_j_test, plot_transforms=True, save_path=None):\n",
    "    # Random picks\n",
    "    print(\"Picking samples\")\n",
    "    X = np.expand_dims(X_test[np.random.choice(len(X_test))], axis=0)\n",
    "    Y = np.expand_dims(Y_test[np.random.choice(len(Y_test))], axis=0)\n",
    "    print(f\"{X.shape = }\")\n",
    "    print(f\"{Y.shape = }\")\n",
    "    \n",
    "    # Transcode\n",
    "    print(\"Performing transcode\")\n",
    "    X_hat = transcoder.selfcode(X, XtoX=True)\n",
    "    Y_hat = transcoder.selfcode(Y, XtoX=False)\n",
    "    Y_fake = transcoder.transcode(X, XtoY=True)\n",
    "    X_fake = transcoder.transcode(Y, XtoY=False)\n",
    "    \n",
    "    # Reconstruct raw spectra\n",
    "    print(\"Denormalizing\")\n",
    "    X_raw = denormalize_features(X, name=\"classical\")\n",
    "    X_raw_hat = denormalize_features(X_hat, name=\"classical\")\n",
    "    X_raw_fake = denormalize_features(X_fake, name=\"classical\")\n",
    "    Y_raw = denormalize_features(Y, name=\"jazz\")\n",
    "    Y_raw_hat = denormalize_features(Y_hat, name=\"jazz\")\n",
    "    Y_raw_fake = denormalize_features(Y_fake, name=\"jazz\")\n",
    "    \n",
    "    # Reconstruct audio\n",
    "    print(\"Reconstructing audio\")\n",
    "    sX = np.squeeze(compute_imels(np.squeeze(X_raw)))\n",
    "    sX_fake = np.squeeze(compute_imels(np.squeeze(X_raw_fake)))\n",
    "    sX_hat = np.squeeze(compute_imels(np.squeeze(X_raw_hat)))\n",
    "    sY = np.squeeze(compute_imels(np.squeeze(Y_raw)))\n",
    "    sY_fake = np.squeeze(compute_imels(np.squeeze(Y_raw_fake)))\n",
    "    sY_hat = np.squeeze(compute_imels(np.squeeze(Y_raw_hat)))\n",
    "    \n",
    "    if save_path is not None:\n",
    "        print(\"Saving audio\")\n",
    "        os.makedirs(save_path, exist_ok = True)\n",
    "        audio_files = [path for path in os.listdir(save_path) if os.path.splitext(path)[-1] == \".wav\"]\n",
    "        \n",
    "        if len(audio_files):\n",
    "            audio_nrs = [int(path.split(\"_\")[0]) for path in audio_files]\n",
    "            audio_nr = max(audio_nrs) + 1\n",
    "        else:\n",
    "            audio_nr = 0\n",
    "        \n",
    "        file_name = f\"{audio_nr}\".zfill(4)\n",
    "        write_audio(sX, os.path.join(save_path, f\"{file_name}_classical.wav\"))\n",
    "        write_audio(sY, os.path.join(save_path, f\"{file_name}_jazz.wav\"))\n",
    "        write_audio(sX_hat, os.path.join(save_path, f\"{file_name}_classical_hat.wav\"))\n",
    "        write_audio(sY_hat, os.path.join(save_path, f\"{file_name}_jazz_hat.wav\"))\n",
    "        write_audio(sX_fake, os.path.join(save_path, f\"{file_name}_classical_fake.wav\"))\n",
    "        write_audio(sY_fake, os.path.join(save_path, f\"{file_name}_jazz_fake.wav\"))\n",
    "    \n",
    "    # Plot raw spectra\n",
    "    if plot_transforms:\n",
    "        print(\"Plotting transforms\")\n",
    "        fig, ax = plot_spectral_feature(X_raw)\n",
    "        ax.set_title(\"Classical Spectrum\")\n",
    "        if save_path is not None:\n",
    "            fig.savefig(os.path.join(save_path, f\"{file_name}_classical.png\"), dpi=300, facecolor=\"white\")\n",
    "        \n",
    "        fig, ax = plot_spectral_feature(X_raw_hat)\n",
    "        ax.set_title(r\"Classical $\\rightarrow$ Classical Spectrum\")\n",
    "        if save_path is not None:\n",
    "            fig.savefig(os.path.join(save_path, f\"{file_name}_classical_hat.png\"), dpi=300, facecolor=\"white\")\n",
    "        \n",
    "        fig, ax = plot_spectral_feature(Y_raw_fake)\n",
    "        ax.set_title(r\"Classical $\\rightarrow$ Jazz Spectrum\")\n",
    "        if save_path is not None:\n",
    "            fig.savefig(os.path.join(save_path, f\"{file_name}_jazz_fake.png\"), dpi=300, facecolor=\"white\")\n",
    "\n",
    "        fig, ax = plot_spectral_feature(Y_raw)\n",
    "        ax.set_title(\"Jazz Spectrum\")\n",
    "        if save_path is not None:\n",
    "            fig.savefig(os.path.join(save_path, f\"{file_name}_jazz.png\"), dpi=300, facecolor=\"white\")\n",
    "        \n",
    "        fig, ax = plot_spectral_feature(Y_raw_hat)\n",
    "        ax.set_title(r\"Jazz $\\rightarrow$ Jazz Spectrum\")\n",
    "        if save_path is not None:\n",
    "            fig.savefig(os.path.join(save_path, f\"{file_name}_jazz_hat.png\"), dpi=300, facecolor=\"white\")\n",
    "        \n",
    "        fig, ax = plot_spectral_feature(X_raw_fake)\n",
    "        ax.set_title(r\"Jazz $\\rightarrow$ Classical Spectrum\")\n",
    "        if save_path is not None:\n",
    "            fig.savefig(os.path.join(save_path, f\"{file_name}_classical_fake.png\"), dpi=300, facecolor=\"white\")\n",
    "\n",
    "        plt.show() \n",
    "    \n",
    "    # Play audio\n",
    "    print(\"Classical audio\")\n",
    "    player = play_audio(sX)\n",
    "    print(\"Classical to Classical audio\")\n",
    "    player = play_audio(sX_hat)\n",
    "    print(\"Classical to Jazz audio\")\n",
    "    player = play_audio(sY_fake)\n",
    "    print()\n",
    "    \n",
    "    print(\"Jazz audio\")\n",
    "    player = play_audio(sY)\n",
    "    print(\"Jazz to Jazz audio\")\n",
    "    player = play_audio(sY_hat)\n",
    "    print(\"Jazz to Classical audio\")\n",
    "    player = play_audio(sX_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transcoders import Conv2DTranscoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"compression\": 4,\n",
    "    \"kernel_size\": 5,\n",
    "    \"conv_depth\": 4,\n",
    "    \"input_chans_multiplier\": 1,\n",
    "    \"skip_connection\": True,\n",
    "    \"pooling_type\": \"average\",\n",
    "    \"h_reg\": 1.,\n",
    "    \"kl_reg\": 0.,\n",
    "}\n",
    "results_path = os.path.join(\"./results/ConvolutionalTranscoder\")\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "transcoder = Conv2DTranscoder(**default_params)\n",
    "transcoder.compile(optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "checkpoint_dir = os.path.join(results_path, \"checkpoints_{epoch:02d}\")\n",
    "checkpoint = krs.callbacks.ModelCheckpoint(\n",
    "    checkpoint_dir,\n",
    "    verbose=True,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "\n",
    "history = transcoder.fit(X_c_train, X_j_train, epochs=50, shuffle=True, callbacks=[checkpoint], validation_data=(X_c_val, X_j_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "for _ in range(25):\n",
    "    test_transcoder(transcoder, save_path=os.path.join(results_path, \"audio\", \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "transcoder.save_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "transcoder = Conv2DTranscoder(**default_params)\n",
    "transcoder.load_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a certain checkpoint\n",
    "checkpoints = [1, 2, 3, 5, 10, 20]\n",
    "n_tests = 5\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    checkpoint_name = f\"checkpoints_{f'{checkpoint}'.zfill(2)}\"\n",
    "    transcoder = Conv2DTranscoder(**default_params)\n",
    "    transcoder.load_weights(os.path.join(results_path, checkpoint_name))\n",
    "    \n",
    "    for _ in range(n_tests):\n",
    "        test_transcoder(transcoder, save_path=os.path.join(results_path, \"audio\", checkpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transcoders import VariationalTranscoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"compression\": 4,\n",
    "    \"kernel_size\": 5,\n",
    "    \"conv_depth\": 4,\n",
    "    \"input_chans_multiplier\": 1,\n",
    "    \"skip_connection\": True,\n",
    "    \"pooling_type\": \"average\",\n",
    "    \"h_reg\": 1e-5,\n",
    "    \"kl_reg\": 1e-12,\n",
    "}\n",
    "results_path = os.path.join(\"./results/VariationalTranscoder\")\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "transcoder = VariationalTranscoder(**default_params)\n",
    "transcoder.compile(optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "checkpoint_dir = os.path.join(results_path, \"checkpoints_{epoch:02d}\")\n",
    "checkpoint = krs.callbacks.ModelCheckpoint(\n",
    "    checkpoint_dir,\n",
    "    verbose=True,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "\n",
    "history = transcoder.fit(X_c_train, X_j_train, epochs=50, callbacks=[checkpoint], shuffle=True, validation_data=(X_c_val, X_j_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test transcoder\n",
    "for _ in range(25):\n",
    "    test_transcoder(transcoder, save_path=os.path.join(results_path, \"audio\", \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transcoder\n",
    "transcoder.save_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcoder\n",
    "transcoder = VariationalTranscoder(**default_params)\n",
    "transcoder.load_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a certain checkpoint\n",
    "checkpoints = [1, 2, 3, 5, 10, 20]\n",
    "n_tests = 5\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    checkpoint_name = f\"checkpoints_{f'{checkpoint}'.zfill(2)}\"\n",
    "    transcoder = VariationalTranscoder(**default_params)\n",
    "    transcoder.load_weights(os.path.join(results_path, checkpoint_name))\n",
    "    \n",
    "    for _ in range(n_tests):\n",
    "        test_transcoder(transcoder, save_path=os.path.join(results_path, \"audio\", checkpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transcoders import GANTranscoder, GANDiscriminators\n",
    "from models.layers import GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan_model(**params):\n",
    "    # Split generator & discriminator params\n",
    "    g_params = {}\n",
    "    d_params = {}\n",
    "    for key, value in params.items():\n",
    "        if key[:2] == \"g_\":\n",
    "            # Generator param\n",
    "            g_params[key[2:]] = value\n",
    "        elif key[:2] == \"d_\":\n",
    "            # Discriminator param\n",
    "            d_params[key[2:]] = value\n",
    "        else:\n",
    "            # Shared param\n",
    "            g_params[key] = value\n",
    "            d_params[key] = value\n",
    "    generator = GANTranscoder(**g_params)\n",
    "    discriminator = GANDiscriminators(**d_params)\n",
    "    gan = GAN(generator, discriminator)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"g_compression\": 4,\n",
    "    \"g_kernel_size\": 5,\n",
    "    \"g_conv_depth\": 4,\n",
    "    \"g_input_chans_multiplier\": 1,\n",
    "    \"g_skip_connection\": True,\n",
    "    \"g_pooling_type\": \"average\",\n",
    "    \"g_gan_reg\": 0.02,\n",
    "    \"g_c_reg\": 0.01,\n",
    "    \"g_s_reg\": 0.01,\n",
    "    \"g_mode\": \"adain\",\n",
    "    \"g_hidden_activation\": \"relu\",\n",
    "    \"g_use_fake_style\": True,\n",
    "    \"d_mlp_layers\": 2,\n",
    "    \"d_conv_layers\": 2,\n",
    "    \"d_conv_kernel_size\": 3,\n",
    "    \"d_conv_pooling_size\": 4,\n",
    "    \"d_conv_pooling_type\": \"max\",\n",
    "}\n",
    "\n",
    "compile_kwargs={\n",
    "    \"g_optimizer\": \"adam\",\n",
    "    \"d_optimizer\": \"adam\",\n",
    "}\n",
    "\n",
    "results_path = os.path.join(\"./results/GANTranscoder\")\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "gan = create_gan_model(**default_params)\n",
    "gan.compile(**compile_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "checkpoint_dir = os.path.join(results_path, \"checkpoints_{epoch:02d}\")\n",
    "checkpoint = krs.callbacks.ModelCheckpoint(\n",
    "    checkpoint_dir,\n",
    "    verbose=True,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "\n",
    "history = gan.fit(X_c_train, X_j_train, epochs=50, shuffle=True, callbacks=[checkpoint], verbose=1, validation_data=(X_c_val, X_j_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "for _ in range(25):\n",
    "    test_transcoder(gan.generator, save_path=os.path.join(results_path, \"audio\", \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transcoder\n",
    "gan.generator.save_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcoder\n",
    "gan = create_gan_model(**default_params)\n",
    "gan.generator.load_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a certain checkpoint\n",
    "checkpoints = [1, 2, 3, 5, 10, 20]\n",
    "n_tests = 5\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    checkpoint_name = f\"checkpoints_{f'{checkpoint}'.zfill(2)}\"\n",
    "    gan = create_gan_model(**default_params)\n",
    "    gan.generator.load_weights(os.path.join(results_path, \"model\"))\n",
    "    \n",
    "    for _ in range(n_tests):\n",
    "        test_transcoder(gan.generator, save_path=os.path.join(results_path, \"audio\", checkpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUNIT Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transcoders import GANTranscoder, GANDiscriminators\n",
    "from models.layers import GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan_model(**params):\n",
    "    # Split generator & discriminator params\n",
    "    g_params = {}\n",
    "    d_params = {}\n",
    "    for key, value in params.items():\n",
    "        if key[:2] == \"g_\":\n",
    "            # Generator param\n",
    "            g_params[key[2:]] = value\n",
    "        elif key[:2] == \"d_\":\n",
    "            # Discriminator param\n",
    "            d_params[key[2:]] = value\n",
    "        else:\n",
    "            # Shared param\n",
    "            g_params[key] = value\n",
    "            d_params[key] = value\n",
    "    generator = GANTranscoder(**g_params)\n",
    "    discriminator = GANDiscriminators(**d_params)\n",
    "    gan = GAN(generator, discriminator)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"feature_shape\": input_shape,\n",
    "    \"g_compression\": 4,\n",
    "    \"g_kernel_size\": 5,\n",
    "    \"g_conv_depth\": 4,\n",
    "    \"g_input_chans_multiplier\": 1,\n",
    "    \"g_skip_connection\": True,\n",
    "    \"g_pooling_type\": \"average\",\n",
    "    \"g_gan_reg\": 0.02,\n",
    "    \"g_c_reg\": 0.01,\n",
    "    \"g_s_reg\": 0.01,\n",
    "    \"g_use_fake_style\": True,\n",
    "    \"g_is_munit\": True,\n",
    "    \"g_style_dim\": 8,\n",
    "    \"g_adain_momentum\": 0.1,\n",
    "    \"g_adain_epsilon\": 1e-5,\n",
    "    \"d_mlp_layers\": 2,\n",
    "    \"d_conv_layers\": 2,\n",
    "    \"d_conv_kernel_size\": 3,\n",
    "    \"d_conv_pooling_size\": 4,\n",
    "    \"d_conv_pooling_type\": \"max\",\n",
    "}\n",
    "\n",
    "compile_kwargs={\n",
    "    \"g_optimizer\": \"adam\",\n",
    "    \"d_optimizer\": \"adam\",\n",
    "}\n",
    "\n",
    "results_path = os.path.join(\"./results/MUNITTranscoder\")\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "gan = create_gan_model(**default_params)\n",
    "gan.compile(**compile_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "checkpoint_dir = os.path.join(results_path, \"checkpoints_{epoch:02d}\")\n",
    "checkpoint = krs.callbacks.ModelCheckpoint(\n",
    "    checkpoint_dir,\n",
    "    verbose=True,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "\n",
    "history = gan.fit(X_c_train, X_j_train, epochs=50, shuffle=True, callbacks=[checkpoint], verbose=1, validation_data=(X_c_val, X_j_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "for _ in range(25):\n",
    "    test_transcoder(gan.generator, save_path=os.path.join(results_path, \"audio\", \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transcoder\n",
    "gan.generator.save_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcoder\n",
    "gan = create_gan_model(**default_params)\n",
    "gan.generator.load_weights(os.path.join(results_path, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a certain checkpoint\n",
    "checkpoints = [1, 2, 3, 5, 10]#, 20]\n",
    "n_tests = 5\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    checkpoint_name = f\"checkpoints_{f'{checkpoint}'.zfill(2)}\"\n",
    "    gan = create_gan_model(**default_params)\n",
    "    gan.generator.load_weights(os.path.join(results_path, \"model\"))\n",
    "    \n",
    "    for _ in range(n_tests):\n",
    "        test_transcoder(gan.generator, save_path=os.path.join(results_path, \"audio\", checkpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
